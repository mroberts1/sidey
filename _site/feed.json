{
    "version": "https://jsonfeed.org/version/1",
    "title": "Martin Roberts",
    "home_page_url": "/",
    "feed_url": "/feed.json",
    "description": "Habitable but too far away to reach",
    "icon": "/apple-touch-icon.png",
    "favicon": "/favicon.ico",
    "expired": false,
    
    "author": "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}",
    
"items": [
    
        {
            "id": "/2021/05/20/tarred-with-the-same-brush",
            "title": "Specters of Media Studies",
            "summary": null,
            "content_text": "My old friend Hugh Gusterson, an  anthropology professor at UBC, asked me on Facebook for my thoughts on Mark Dery’s  article about the latest imbroglio at NYU, this time involving not Avital Ronell but media professor/conspiracy theorist Mark Crispin Miller.I must admit that I hadn’t heard about this particular shitstorm - we lead sheltered lives on the internet - but as chance would have it, I taught for a number of years in Miller’s department and even occasionally shared an elevator with the defendant. At that time, Neil Postman was still chair of what was grandly known as the Department of Media Ecology (not in the contemporary sense), so I’m broadly familiar with - albeit not sympathetic to - the particular current of media criticism that Miller represents. Since my hot take on Dery’s article was too long for a Facebook comment, I’ve put it up here instead.  “Was there always a conspiratorial undertow to media studies, a paranoid style of mind that might make the transition from ‘media monopoly’ to ‘deep state’ easier than it seems?”As if we needed an answer. As if, indeed, we needed yet another nail in the coffin of media studies, the academic discipline that everyone outside it has loved to hate for the past forty years. That narrative may be somewhat plausible of the U.S. version of the field, arguably just an update of old-school U.S. communication studies: propaganda, psy-ops, the hidden persuaders, corporate oligarchies, mind control: Postman, Miller, Todd Gitlin, Terry Moran, Ben Bagdikian, Noam Chomsky, Ed Herman, Bob McChesney - this has always been a men-only club.The problem is that narrative also conflates that club with the field in its entirety, as if an entire generation of scholarship from the UK, Australia, India, Asia, and Latin America - much of which has carried out a comprehensive critique of the premises of US comm studies - had simply never existed. In this worldview, the work of Stuart Hall, Paul Gilroy, Angela McRobbie, John Fiske, Toby Miller, Ien Ang, Meaghan Morris, John Frow, Rey Chow, Ken Gelder, Ariel Dorfman, Nestor García Canclini, Arjun Appadurai, and many more are presumably deemed to belong to cultural studies rather than media studies “proper” - despite Dery’s description of media studies as a “genre-hopping, metadiscursive field.”I suspect that some of the pronouncements I heard from Neil Postman’s mouth at the time might not have stood up well to Dery’s scrutiny either, but 9/11 and Sandy Hook hadn’t happened yet and even Neil wasn’t advocating that the moon landing was shot on a soundstage. He was just what we younger types called “old school,” the way Miller is - at 71 -  also old school, albeit in this case several steps closer to full-on Roswell.So in this narrowly US-centric idea of media studies - which I would call communication studies - someone like Miller becomes just another way of taking out an entire academic field, adding to the journalistic choir seeking to make media studies - or what it takes media studies to be - the unwitting enabler of truther conspiracy theories and cancel culture. After all, why is at a problem, really, if Miller is also being held to account for transphobia in addition to promoting conspiracy theories, as if that was merely an irrelevant detail?So while I’m basically sympathetic to Dery’s line of argument, I’m also dismayed to see how seamlessly it elides Miller’s inexplicable embrace of conspiracy theories with the academic field that he supposedly represents. He doesn’t, although I think his conspiracy thinking is not as anomalous in “credible and credentialed” sources as Dery seems to believe (I’m looking at you, Adam Curtis). But that doesn’t justify generalizing it as symptomatic of the discipline more generally. Critiques of conspiracy culture itself have for some time now been a significant sub-field of media studies - as well they might. Does Avital Ronell mean that continental theory is just a power trip? Does a Columbia professor of Korean Studies being exposed as a plagiarist now mean that the entire field is corrupt?Conspiracy theories are like cults: you can’t just argue people out of them because they’re impermeable to argumentation or evidence: you’re just treated as part of the conspiracy. It reminds me of a story a college chaplain told me many years ago, about trying to reason with a guy who believed he was the reincarnation of Jesus: “yes, they tried to tell me I wasn’t the Messiah two thousand years ago.” While hopefully even Miller is not labouring under that kind of misapprehension, to treat his idiosyncrasies as representative of the malaise of the academic field at large seems like its own particular kind of pathology: the desire, once and for all, to lay the specter of media studies to rest.But if there’s one thing that the media studies sub-field known as hauntology has taught us, it’s that vampires, zombies, and other phantoms aren’t so easily exorcised  from the collective unconscious; indeed, what’s most shocking (to me, at least) about Miller’s views isn’t how deviant but how familiar, even conventional they are in the pop-cultural mainstream. What Erik Davis calls “High Weirdness” is today not nearly as outlandish as he and many others like to tell each other on their podcasts. I would thus see someone like Miller less as a delusional lone shooter and more like a sign o’ the times. As an early adopter of Afrofuturism, I’m quite surprised that Dery acts like the smart kid who wanders into the bar of the New Weird America and discovers Miller hanging out with the locals. Maybe it just started out as participant observation, but he would hardly be the first ethnographer to end up going native.",
            "content_html": "<p>My old friend <a href=\"https://anth.ubc.ca/profile/hugh-gusterson/\">Hugh Gusterson</a>, an  anthropology professor at UBC, asked me on Facebook for my thoughts on Mark Dery’s  <a href=\"https://www.chronicle.com/article/the-professor-of-paranoia?utm_source=Iterable&amp;utm_medium=email&amp;utm_campaign=campaign_2350474_nl_Academe-Today_date_20210518&amp;cid=at&amp;source=&amp;sourceId=&amp;fbclid=IwAR0Rr9PT0KZu608wBgdNmXrmHsOg97GH7ngECXjsE0svXo8-0_spds6y-Qw\">article</a> about the latest imbroglio at NYU, this time involving not <a href=\"https://www.chronicle.com/article/i-worked-with-avital-ronell-i-believe-her-accuser/\">Avital Ronell</a> but media professor/conspiracy theorist Mark Crispin Miller.</p><p>I must admit that I hadn’t heard about this particular shitstorm - we lead sheltered lives on the internet - but as chance would have it, I taught for a number of years in Miller’s department and even occasionally shared an elevator with the defendant. At that time, Neil Postman was still chair of what was grandly known as the Department of Media Ecology (not in the contemporary sense), so I’m broadly familiar with - albeit not sympathetic to - the particular current of media criticism that Miller represents. Since my hot take on Dery’s article was too long for a Facebook comment, I’ve put it up here instead.</p><blockquote>  <p>“Was there always a conspiratorial undertow to media studies, a paranoid style of mind that might make the transition from ‘media monopoly’ to ‘deep state’ easier than it seems?”</p></blockquote><p>As if we needed an answer. As if, indeed, we needed yet another nail in the coffin of media studies, the academic discipline that everyone outside it has loved to hate for the past forty years. That narrative may be somewhat plausible of the U.S. version of the field, arguably just an update of old-school U.S. communication studies: propaganda, psy-ops, the hidden persuaders, corporate oligarchies, mind control: Postman, Miller, Todd Gitlin, Terry Moran, Ben Bagdikian, Noam Chomsky, Ed Herman, Bob McChesney - this has always been a men-only club.</p><p>The problem is that narrative also conflates that club with the field in its entirety, as if an entire generation of scholarship from the UK, Australia, India, Asia, and Latin America - much of which has carried out a comprehensive critique of the premises of US comm studies - had simply never existed. In this worldview, the work of Stuart Hall, Paul Gilroy, Angela McRobbie, John Fiske, Toby Miller, Ien Ang, Meaghan Morris, John Frow, Rey Chow, Ken Gelder, Ariel Dorfman, Nestor García Canclini, Arjun Appadurai, and many more are presumably deemed to belong to cultural studies rather than media studies “proper” - despite Dery’s description of media studies as a “genre-hopping, metadiscursive field.”</p><p>I suspect that some of the pronouncements I heard from Neil Postman’s mouth at the time might not have stood up well to Dery’s scrutiny either, but 9/11 and Sandy Hook hadn’t happened yet and even Neil wasn’t advocating that the moon landing was shot on a soundstage. He was just what we younger types called “old school,” the way Miller is - at 71 -  also old school, albeit in this case several steps closer to full-on Roswell.</p><p>So in this narrowly US-centric idea of media studies - which I would call communication studies - someone like Miller becomes just another way of taking out an entire academic field, adding to the journalistic choir seeking to make media studies - or what it takes media studies to be - the unwitting enabler of truther conspiracy theories and cancel culture. After all, why is at a problem, really, if Miller is also being held to account for transphobia in addition to promoting conspiracy theories, as if that was merely an irrelevant detail?</p><p>So while I’m basically sympathetic to Dery’s line of argument, I’m also dismayed to see how seamlessly it elides Miller’s inexplicable embrace of conspiracy theories with the academic field that he supposedly represents. He doesn’t, although I think his conspiracy thinking is not as anomalous in “credible and credentialed” sources as Dery seems to believe (I’m looking at you, Adam Curtis). But that doesn’t justify generalizing it as symptomatic of the discipline more generally. Critiques of conspiracy culture itself have for some time now been a significant sub-field of media studies - as well they might. Does Avital Ronell mean that continental theory is just a power trip? Does a Columbia professor of Korean Studies being <a href=\"http://sthelepress.com/index.php/2016/09/13/revoking-a-recommendation-b-r-myers/\">exposed as a plagiarist</a> now mean that the entire field is corrupt?</p><p>Conspiracy theories are like cults: you can’t just argue people out of them because they’re impermeable to argumentation or evidence: you’re just treated as part of the conspiracy. It reminds me of a story a college chaplain told me many years ago, about trying to reason with a guy who believed he was the reincarnation of Jesus: “yes, they tried to tell me I wasn’t the Messiah two thousand years ago.” While hopefully even Miller is not labouring under that kind of misapprehension, to treat his idiosyncrasies as representative of the malaise of the academic field at large seems like its own particular kind of pathology: the desire, once and for all, to lay the specter of media studies to rest.</p><p>But if there’s one thing that the media studies sub-field known as hauntology has taught us, it’s that vampires, zombies, and other phantoms aren’t so easily exorcised  from the collective unconscious; indeed, what’s most shocking (to me, at least) about Miller’s views isn’t how deviant but how familiar, even conventional they are in the pop-cultural mainstream. What Erik Davis calls “High Weirdness” is today not nearly as outlandish as he and many others like to tell each other on their podcasts. I would thus see someone like Miller less as a delusional lone shooter and more like a sign o’ the times. As an early adopter of Afrofuturism, I’m quite surprised that Dery acts like the smart kid who wanders into the bar of the New Weird America and discovers Miller hanging out with the locals. Maybe it just started out as participant observation, but he would hardly be the first ethnographer to end up going native.</p>",
            "url": "/2021/05/20/tarred-with-the-same-brush",
            
            
            
            
            
            "date_published": "2021-05-20T00:00:00-04:00",
            "date_modified": "2021-05-20T00:00:00-04:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "/2021/01/24/shiny-happy-templates",
            "title": "Shiny Happy Templates",
            "summary": "A year in web design",
            "content_text": "A year in web designIn the Spring of last year, while working at a university writing center in Jeonju, South Korea, I unexpectedly found myself with a lot of free evenings. Part of my job involved authoring an online study guide on academic writing in English for the center’s website. The process began with me authoring documents in Microsoft Word, which after receiving the director’s approval were outsourced to a web design company that converted them to HTML documents and uploaded them to the center’s website. I wasn’t too happy either with the generic design of the website or the absence of control over the design process itself, and for the first time in years  began experimenting with authoring content directly to web pages. Abandoning Microsoft Word other than for editing author manuscripts, I switched more or less overnight to authoring documents in Markdown and converting them to whatever format was needed, whether docx, html, or pdf. I discovered that unlike people in humanities fields who continue to struggle with MS Word bloatware, scientists have been using Latex for decades to author beautifully-formatted manuscripts. I finally, belatedly discovered the work of Edward Tufte, whose name I’d sporadically come across over previous decades but whose contribution to the field of visual design I’ve only come to realize over the past year. I was particularly taken with the exquisite design of Tufte’s books and website, and - again for the first time - began scouring typography websites and hunting down font libraries to improve on the lackluster fonts that are standard on most websites.I started by exploring the proliferating field of minimalist, “distraction-free” writing apps, whether standalone like Sublime Text or iA / Writer, or the growing number of browser-based apps like Write.as or Sigle. The Javascript-based online apps looked cool and were designed to be as easy to use as possible, but I couldn’t take to them, and every one I tried seemed to have some limitation that led me to move on to another one: as soon as I tentatively tried a sample post or two, I would run into some design element I didn’t like but couldn’t change. It quickly became obvious that what I really wanted was greater agency in deciding how my content looked, rather than just pouring it into predesigned templates.By now I’d begun to fall down a number of other rabbit holes that seemed to be offer something closer to what I was looking for: RStudio, an authoring environment that automated the process of generating PDF documents, websites, and even entire books from Markdown documents; Jekyll, another blog-authoring framework with an extensive library of themes; and Hugo, Jekyll’s cooler younger brother. While web-design apps like Wordpress streamlined the design process to the point that it became like painting by numbers, frameworks like Jekyll and Hugo required use of the command line interface, which I’d used long before and felt I  still knew my way around, kind of. I even had a GitHub account, although at the time still had little idea what to do with it. Gradually, as the spring evenings wore on, I reached the decision that what I really needed to do was to get back into web development. After all, wasn’t this long overdue? Hadn’t I started out authoring HTML pages and websites myself in the very earliest days of the web? Hadn’t I used blogs as a teaching tool when I taught courses on interactive media in the early 2000s? Wouldn’t it be worthwhile to catch up on what had been going on in web design over the two decades since I’d been making little websites with Dreamweaver? It was high  time I established some kind of online presence. Like many people, I was becoming increasingly disillusioned with social media and the corporate takeover of the web, yet most people in my field continued to use the walled gardens of platform capitalism. Every alternative I looked into reassured me how easy it all was: everbody else, it seemed, was hosting blogs, generating static websites, building wikis. I was late to the party, as usual, but I still wanted to join it. So I decided to go back to web development.And that’s where my troubles really started.",
            "content_html": "<p><strong>A year in web design</strong></p><p>In the Spring of last year, while working at a university writing center in Jeonju, South Korea, I unexpectedly found myself with a lot of free evenings. Part of my job involved authoring an online study guide on academic writing in English for the center’s website. The process began with me authoring documents in Microsoft Word, which after receiving the director’s approval were outsourced to a web design company that converted them to HTML documents and uploaded them to the center’s website. I wasn’t too happy either with the generic design of the website or the absence of control over the design process itself, and for the first time in years  began experimenting with authoring content directly to web pages. Abandoning Microsoft Word other than for editing author manuscripts, I switched more or less overnight to authoring documents in <a href=\"https://daringfireball.net/projects/markdown/\">Markdown</a> and converting them to whatever format was needed, whether docx, html, or pdf. I discovered that unlike people in humanities fields who continue to struggle with MS Word bloatware, scientists have been using Latex for decades to author beautifully-formatted manuscripts. I finally, belatedly discovered the work of <a href=\"https://www.edwardtufte.com/tufte/courses\">Edward Tufte</a>, whose name I’d sporadically come across over previous decades but whose contribution to the field of visual design I’ve only come to realize over the past year. I was particularly taken with the exquisite design of Tufte’s books and website, and - again for the first time - began scouring typography websites and hunting down font libraries to improve on the lackluster fonts that are standard on most websites.</p><p>I started by exploring the proliferating field of minimalist, “distraction-free” writing apps, whether standalone like <a href=\"https://www.sublimetext.com/\">Sublime Text</a> or <a href=\"https://ia.net/writer\">iA / Writer</a>, or the growing number of browser-based apps like <a href=\"https://write.as/\">Write.as</a> or <a href=\"https://www.sigle.io/\">Sigle</a>. The Javascript-based online apps looked cool and were designed to be as easy to use as possible, but I couldn’t take to them, and every one I tried seemed to have some limitation that led me to move on to another one: as soon as I tentatively tried a sample post or two, I would run into some design element I didn’t like but couldn’t change. It quickly became obvious that what I really wanted was greater agency in deciding how my content looked, rather than just pouring it into predesigned templates.</p><p>By now I’d begun to fall down a number of other rabbit holes that seemed to be offer something closer to what I was looking for: <a href=\"https://rstudio.com/\">RStudio</a>, an authoring environment that automated the process of generating PDF documents, <a href=\"https://bookdown.org/yihui/blogdown/\">websites</a>, and even entire <a href=\"https://bookdown.org/yihui/bookdown/\">books</a> from Markdown documents; <a href=\"https://jekyllrb.com/\">Jekyll</a>, another blog-authoring framework with an extensive library of themes; and <a href=\"https://gohugo.io/\">Hugo</a>, Jekyll’s cooler younger brother. While web-design apps like <a href=\"https://wordpress.com/\">Wordpress</a> streamlined the design process to the point that it became like painting by numbers, frameworks like Jekyll and Hugo required use of the command line interface, which I’d used long before and felt I  still knew my way around, kind of. I even had a <a href=\"https://github.com/mroberts1\">GitHub account</a>, although at the time still had little idea what to do with it. Gradually, as the spring evenings wore on, I reached the decision that what I really needed to do was to get back into web development. After all, wasn’t this long overdue? Hadn’t I started out authoring HTML pages and websites myself in the very earliest days of the web? Hadn’t I used blogs as a teaching tool when I taught courses on interactive media in the early 2000s? Wouldn’t it be worthwhile to catch up on what had been going on in web design over the two decades since I’d been making little websites with Dreamweaver? It was high  time I established some kind of online presence. Like many people, I was becoming increasingly disillusioned with social media and the corporate takeover of the web, yet most people in my field continued to use the walled gardens of platform capitalism. Every alternative I looked into reassured me how easy it all was: everbody else, it seemed, was hosting blogs, generating static websites, building wikis. I was late to the party, as usual, but I still wanted to join it. So I decided to go back to web development.</p><p>And that’s where my troubles really started.</p>",
            "url": "/2021/01/24/shiny-happy-templates",
            
            
            
            
            
            "date_published": "2021-01-24T00:00:00-05:00",
            "date_modified": "2021-01-24T00:00:00-05:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        },
    
        {
            "id": "/2021/01/18/forget-the-future",
            "title": "Forget The Future",
            "summary": null,
            "content_text": "Monday 18 January 2021I’m riding in the front passenger seat of my sister-in-law’s pure-white  Hyundai Grandeur on the way to my wife’s hospital appointment early on a Monday morning, cruising though commuter traffic in Seoul, along a tributary of the great Han river that flows through the city. The car is new and its  dashboard is state-of-the-art: the widescreen navigation system is the size of my laptop and auto-zooms in and out as we approach intersections, while the on-board entertainment module looks like the interface of a home theater system. As the urban landscape scrolls smoothly past in an endless loop of high-rise apartment complexes and riverside exercise parks, I watch the other, very similar black and white cars gliding smoothly around us, and find myself wondering what all this will look like a hundred years from now. And it occurs to me that it will probably not look all that different from how it does today. There will still be no flying cars, for the same economic and logistical reasons there are no flying cars now; cars themselves will almost certainly still be around, though, powered by today’s alternative energy sources: electric, hydrogen, solar (probably still not wind). The apartment villages will also likely still be around, in higher, more futuristic form. In spite of a century of further global warming, viral pandemics, and inevitably, wars; in spite of the continued expansion of environmentally-responsible, low-tech, post-capitalist lifestyles, centuries-old habits die hard. As my sister-in-law’s car shows, while technologies change, in modern societies human needs remain pretty consistent: automation, seamless mobility, continuous connectivity, convenience stores, online shopping, home delivery, streaming entertainment. In many ways, the hikikomori life under lockdown over the past year has already given us a preview of what life will be like in the coming century: biocitizenship, social control, auto-surveillance, remote interfaces. Welcome to the future. On our network screens, people keep reminding us that even when the present pandemic ends - if it even does - life from now on will never be the same as it was before. Because one guy twenty years ago concealed a bomb in his shoe before boarding an airliner, we now all have to go barefoot through airport security.In thinking about the future, we tend to forget the inertia of the status quo: a kind of structural viscosity that is resistant to sudden social transformation and seeks to preserve existing power and economic relations. We know that such transformations can happen and have happened historically, of course, but in the larger scheme of things they belong to the same order as earthquakes or plane crashes: freak events that are catastrophic but relatively rare.So ultimately, I don’t think speculating about the future, either in utopian or dystopian terms, is all that interesting, because I think the future - at least the foreseeable future -  is going to look very much like the present, albeit with cooler-looking technology. At this point, modernity is a train that has come off the tracks, but continues to plough on regardlessly: while capitalist realism may be an ideology, as Mark Fisher has convincingly demonstrated, modernity itself is a much larger vehicle, a juggernaut driven by economic logics rather than ethical or environmental concerns. In this still modern, capitalist world, it remains  unimaginable that a hundred years from now the high-rise complexes, the freeways, the commuter traffic, and the exercise parks will have been replaced by an arcadia of green spaces, intentional communities, solarpunk bike messengers, non-plastic-clogged oceans, and resurgent animal species. Some of these things will hopefully exist parallel to the viscous world, of course, and we must not relax our efforts to achieve them. But achieving them will require a continuous struggle against the forces of inertia, the vested interests of the political and economic incumbents. And we should be under no illusions about the forces of inertia that any effort to imagine - let alone realize - a less alienating, more just, more fulfilling world will be up against.Forty years ago, the French social theorist and arch-provocateur Jean Baudrillard, in a typical act of philosophical heresy, invited us to forget the work of the great social historian Michel Foucault, in a work simply titled in English Forget Foucault (the French Oublier Foucault, “forgetting Foucault,” is less blunt). To propose a similar act of forgetting in the case of the future might seem perverse, given that forgetting itself is something that in theory at least could only be done to something that has already happened, not what has not yet happened. But the future itself has a history, and that history shows that we have been wrong about the future many times before. So that is why I propose that we need to forget about the future, remember that we live only in the present, and focus on improving things there first, if we are to make a better world, whether tomorrow or a hundred years from now.",
            "content_html": "<p><em>Monday 18 January 2021</em></p><p>I’m riding in the front passenger seat of my sister-in-law’s pure-white  Hyundai Grandeur on the way to my wife’s hospital appointment early on a Monday morning, cruising though commuter traffic in Seoul, along a tributary of the great Han river that flows through the city. The car is new and its  dashboard is state-of-the-art: the widescreen navigation system is the size of my laptop and auto-zooms in and out as we approach intersections, while the on-board entertainment module looks like the interface of a home theater system. As the urban landscape scrolls smoothly past in an endless loop of high-rise apartment complexes and riverside exercise parks, I watch the other, very similar black and white cars gliding smoothly around us, and find myself wondering what all this will look like a hundred years from now. And it occurs to me that it will probably not look all that different from how it does today. There will still be no <a href=\"https://thebaffler.com/salvos/of-flying-cars-and-the-declining-rate-of-profit\">flying cars</a>, for the same economic and logistical reasons there are no flying cars now; cars themselves will almost certainly still be around, though, powered by today’s alternative energy sources: electric, hydrogen, solar (probably still not wind). The apartment villages will also likely still be around, in higher, more futuristic form. In spite of a century of further global warming, viral pandemics, and inevitably, wars; in spite of the continued expansion of environmentally-responsible, low-tech, post-capitalist lifestyles, centuries-old habits die hard. As my sister-in-law’s car shows, while technologies change, in modern societies human needs remain pretty consistent: automation, seamless mobility, continuous connectivity, convenience stores, online shopping, home delivery, streaming entertainment. In many ways, the <em>hikikomori</em> life under lockdown over the past year has already given us a preview of what life will be like in the coming century: biocitizenship, social control, auto-surveillance, remote interfaces. Welcome to the future. On our network screens, people keep reminding us that even when the present pandemic ends - if it even does - life from now on will never be the same as it was before. Because one guy twenty years ago concealed a bomb in his shoe before boarding an airliner, we now all have to go barefoot through airport security.</p><p>In thinking about the future, we tend to forget the inertia of the status quo: a kind of structural viscosity that is resistant to sudden social transformation and seeks to preserve existing power and economic relations. We know that such transformations can happen and have happened historically, of course, but in the larger scheme of things they belong to the same order as earthquakes or plane crashes: freak events that are catastrophic but relatively rare.</p><p>So ultimately, I don’t think speculating about the future, either in utopian or dystopian terms, is all that interesting, because I think the future - at least the foreseeable future -  is going to look very much like the present, albeit with cooler-looking technology. At this point, modernity is a train that has come off the tracks, but continues to plough on regardlessly: while capitalist realism may be an ideology, as <a href=\"https://www.johnhuntpublishing.com/zer0-books/our-books/capitalist-realism\">Mark Fisher</a> has convincingly demonstrated, modernity itself is a much larger vehicle, a juggernaut driven by economic logics rather than ethical or environmental concerns. In this still modern, capitalist world, it remains  unimaginable that a hundred years from now the high-rise complexes, the freeways, the commuter traffic, and the exercise parks will have been replaced by an arcadia of green spaces, intentional communities, solarpunk bike messengers, non-plastic-clogged oceans, and resurgent animal species. Some of these things will hopefully exist parallel to the viscous world, of course, and we must not relax our efforts to achieve them. But achieving them will require a continuous struggle against the forces of inertia, the vested interests of the political and economic incumbents. And we should be under no illusions about the forces of inertia that any effort to imagine - let alone realize - a less alienating, more just, more fulfilling world will be up against.</p><p>Forty years ago, the French social theorist and arch-provocateur Jean Baudrillard, in a typical act of philosophical heresy, invited us to forget the work of the great social historian Michel Foucault, in a work simply titled in English <a href=\"http://semiotexte.com/?p=704\"><em>Forget Foucault</em></a> (the French <em>Oublier Foucault</em>, “forgetting Foucault,” is less blunt). To propose a similar act of forgetting in the case of the future might seem perverse, given that forgetting itself is something that in theory at least could only be done to something that has already happened, not what has not yet happened. But the future itself has a history, and that history shows that we have been wrong about the future many times before. So that is why I propose that we need to forget about the future, remember that we live only in the present, and focus on improving things there first, if we are to make a better world, whether tomorrow or a hundred years from now.</p>",
            "url": "/2021/01/18/forget-the-future",
            
            
            
            "tags": ["future","seoul"],
            
            "date_published": "2021-01-18T00:00:00-05:00",
            "date_modified": "2021-01-18T00:00:00-05:00",
            
                "author": 
                "{"twitter"=>nil, "name"=>nil, "avatar"=>nil, "email"=>nil, "url"=>nil}"
                
            
        }
    
    ]
}